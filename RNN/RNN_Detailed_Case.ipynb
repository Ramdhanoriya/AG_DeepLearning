{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "import os\n",
    "from importlib import reload\n",
    "\n",
    "def set_keras_backend(backend):\n",
    "\n",
    "    if K.backend() != backend:\n",
    "        os.environ['KERAS_BACKEND'] = backend\n",
    "        reload(K)\n",
    "        assert K.backend() == backend\n",
    "\n",
    "set_keras_backend(\"tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"with open(('wonderland.txt'), 'rb') as document:\\n  response = document_conversion.convert_document(document=document, config=config)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"with open(('wonderland.txt'), 'rb') as document:\n",
    "  response = document_conversion.convert_document(document=document, config=config)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"wonderland.txt\"\n",
    "raw_text = open(text, encoding=\"utf8\").read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144225"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = 100\n",
    "XX = []\n",
    "YY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    XX.append([char_to_int[char] for char in seq_in])\n",
    "    YY.append(char_to_int[seq_out])\n",
    "n_patterns = len(XX)\n",
    "n_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = numpy.reshape(XX, (n_patterns, seq_length, 1))\n",
    "X = X / float(n_vocab)\n",
    "y = np_utils.to_categorical(YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "print(multiprocessing.cpu_count()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multi_gpu as mg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Palash Goyal\\Documents\\DeepLearning\\Blog\\multi_gpu.py:44: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  merged.append(merge(outputs, mode='concat', concat_axis=0))\n",
      "C:\\Users\\Palash Goyal\\AppData\\Roaming\\Python\\Python35\\site-packages\\keras-2.0.5-py3.5.egg\\keras\\legacy\\layers.py:460: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "C:\\Users\\Palash Goyal\\Documents\\DeepLearning\\Blog\\multi_gpu.py:46: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n",
      "  return Model(input=model.inputs, output=merged)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model = mg.make_parallel(model, multiprocessing.cpu_count())\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(X, y, epochs=20, batch_size=64, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:\n",
      "\" tried\n",
      "hedges,’ the pigeon went on, without attending to her; ‘but those\n",
      "serpents! there’s no p \"\n",
      "ice the shattee onte the toaas then!�\n",
      "the aaded inoa"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "filename = \"weights-improvement-47-1.6669.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "start = numpy.random.randint(0, len(XX)-1)\n",
    "pattern = XX[start]\n",
    "print \"Start:\"\n",
    "print \"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\"\n",
    "for i in range(100):\n",
    "                x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "                x = x / float(n_vocab)\n",
    "                prediction = model.predict(x, verbose=0)\n",
    "                index = numpy.argmax(prediction)\n",
    "                result = int_to_char[index]\n",
    "                seq_in = [int_to_char[value] for value in pattern]\n",
    "                sys.stdout.write(result)\n",
    "                pattern.append(index)\n",
    "                pattern = pattern[1:len(pattern)]\n",
    "print \"\\nEnd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
